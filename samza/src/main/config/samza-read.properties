# Job
job.factory.class=org.apache.samza.job.local.ThreadJobFactory
job.name=samze-demo-job

# Job Coordinator
job.coordinator.system=kafka
# Add configuration to disable checkpointing for this job once it is available in the Coordinator Stream model
# See https://issues.apache.org/jira/browse/SAMZA-465?focusedCommentId=14533346&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14533346 for more details
job.coordinator.replication.factor=1

# YARN
yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.container.memory.mb=2560

# Task
task.class=com.samza.examples.SamzaRead
#task.class=com.rasa.cloud.samza.amon.AmonParser
task.inputs=kafka.test1,kafka.test
#task.inputs=kafka.CPacketStream
	# name of the input stream. Careful! if it is changed here, also need to change it in line 51 below
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
# Normally, this would be 3, but we have only one broker.
task.checkpoint.replication.factor=1

# Task timing
task.window.ms=60000

# FIXME: this is a stop-gap measure to work around the issues with CentOS netlib loading native BLAS/LAPACK
# This forces netlib to use the java implementations (which are slow)
# See JIRA issue RASA-537
task.opts=-Xmx1024M -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS -Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.F2jLAPACK -Dcom.github.fommil.netlib.ARPACK=com.github.fommil.netlib.F2jARPACK

# Metrics
# Define a metrics reporter called "snapshot", which publishes metrics
# every 60 seconds.
metrics.reporters=snapshot
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory

# Tell the snapshot reporter to publish to a topic called "metrics"
# in the "kafka" system.
metrics.reporter.snapshot.stream=kafka.metrics

# Encode metrics data as JSON.
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
systems.kafka.streams.metrics.samza.msg.serde=metrics

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=byte
systems.kafka.consumer.zookeeper.connect=localhost:2181/
systems.kafka.producer.bootstrap.servers=localhost:9092

# Define a serde called "avro" which parses/serializes Avro objects

serializers.registry.byte.class=org.apache.samza.serializers.ByteSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory



## Kafka stream settings: it does not make sense to generate clock sync correction messages based on old data
systems.kafka.samza.offset.default=upcoming
    # when job starts, start processing at the tail of the stream (don't read old messages)
systems.kafka.streams.PacketStream.samza.reset.offset=true
    # when job starts, ignore checkpointed offsets for this stream, and go to the tail of the stream
    # (as per systems.kafka.samza.offset.default above) 
systems.kafka.consumer.auto.offset.reset=largest
	# if invalid offsets occur, skip to tail of stream 

# Job-specific settings
